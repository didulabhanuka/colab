{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/didulabhanuka/colab/blob/main/yoloV8_tomato_ripeness_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Install Required Libraries"
      ],
      "metadata": {
        "id": "hwYZhAuccG0d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yvf9_letKmVS"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics albumentations torchvision pycocotools fiftyone\n",
        "!pip install flask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Import Required Libraries & Mount Google Drive"
      ],
      "metadata": {
        "id": "6-qcdIcscKU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "khtYRXy_Lz4E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "from albumentations import Compose, RandomBrightnessContrast, HueSaturationValue, GaussianBlur, MotionBlur, Normalize\n",
        "from ultralytics import YOLO\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from PIL import Image # Import the Image class from the PIL library\n",
        "import torchvision.transforms as transforms # Import transforms\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Create YAML File for Dataset Configuration"
      ],
      "metadata": {
        "id": "1shVfhrTcMYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHJUPOo7OH91"
      },
      "outputs": [],
      "source": [
        "yaml_content = \"\"\"\n",
        "train: /content/dataset_augmented/train\n",
        "val: /content/dataset_augmented/val\n",
        "\n",
        "nc: 6\n",
        "names: [\"b_fully_ripened\", \"b_half_ripened\", \"b_green\", \"l_fully_ripened\", \"l_half_ripened\", \"l_green\"]\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = \"/content/tomato_ripeness_classifier.yaml\"\n",
        "with open(yaml_path, \"w\") as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "print(f\"YAML file created at {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Extract Dataset from Google Drive"
      ],
      "metadata": {
        "id": "PqpnpROjcUy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "da-73rouOLMV"
      },
      "outputs": [],
      "source": [
        "dataset_zip = \"/content/drive/MyDrive/tomato_ripeness_classifier/tomato_dataset.zip\"\n",
        "dataset_dir = \"/content/dataset/dataset\"\n",
        "\n",
        "os.makedirs(\"/content/dataset\", exist_ok=True)\n",
        "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/dataset\")\n",
        "\n",
        "print(\"Dataset unzipped successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Data Augmentation"
      ],
      "metadata": {
        "id": "zzLfGK5ScS6m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFZYrNBGONmw"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "augmented_dir = \"/content/dataset_augmented\"\n",
        "\n",
        "# Create Augmented Dataset Folders\n",
        "os.makedirs(f\"{augmented_dir}/train/images\", exist_ok=True)\n",
        "os.makedirs(f\"{augmented_dir}/train/labels\", exist_ok=True)\n",
        "os.makedirs(f\"{augmented_dir}/val/images\", exist_ok=True)\n",
        "os.makedirs(f\"{augmented_dir}/val/labels\", exist_ok=True)\n",
        "\n",
        "def denormalize_image(image):\n",
        "    \"\"\"\n",
        "    Reverts normalization to bring pixel values back to [0,255].\n",
        "    \"\"\"\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "    # Undo normalization\n",
        "    image = image * std + mean  # Reverse normalization\n",
        "    image = np.clip(image * 255, 0, 255).astype(np.uint8)  # Convert to 0-255 range\n",
        "\n",
        "    return image\n",
        "\n",
        "def validate_and_clip_bbox(bbox, img_w, img_h):\n",
        "    \"\"\"\n",
        "    Ensures bounding box values stay within valid ranges.\n",
        "    \"\"\"\n",
        "    x_center, y_center, width, height = bbox\n",
        "    x_center /= img_w\n",
        "    y_center /= img_h\n",
        "    width /= img_w\n",
        "    height /= img_h\n",
        "\n",
        "    x_center = np.clip(x_center, 0.0, 1.0)\n",
        "    y_center = np.clip(y_center, 0.0, 1.0)\n",
        "    width = np.clip(width, 0.0, 1.0)\n",
        "    height = np.clip(height, 0.0, 1.0)\n",
        "\n",
        "    x_min = x_center - width / 2\n",
        "    y_min = y_center - height / 2\n",
        "    x_max = x_center + width / 2\n",
        "    y_max = y_center + height / 2\n",
        "\n",
        "    if 0.0 <= x_min <= 1.0 and 0.0 <= y_min <= 1.0 and 0.0 <= x_max <= 1.0 and 0.0 <= y_max <= 1.0 and width > 0 and height > 0:\n",
        "        return [x_center, y_center, width, height]\n",
        "    return None  # Invalid bbox\n",
        "\n",
        "def advanced_augmentations(image_folder, label_folder, output_image_folder, output_label_folder):\n",
        "    \"\"\"\n",
        "    Applies augmentations while keeping bounding boxes correctly aligned.\n",
        "    \"\"\"\n",
        "    augmentations = Compose(\n",
        "        [\n",
        "            RandomBrightnessContrast(p=0.2),\n",
        "            HueSaturationValue(p=0.2),\n",
        "            GaussianBlur(p=0.1),\n",
        "            MotionBlur(p=0.1),\n",
        "            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Applied for training\n",
        "        ],\n",
        "        bbox_params={\"format\": \"yolo\", \"label_fields\": [\"class_labels\"]},\n",
        "    )\n",
        "\n",
        "    for image_file in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, image_file)\n",
        "        label_path = os.path.join(label_folder, os.path.splitext(image_file)[0] + \".txt\")\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"Skipping {image_file}: Unable to read image.\")\n",
        "            continue\n",
        "\n",
        "        h, w, _ = image.shape\n",
        "        bboxes = []\n",
        "        class_labels = []\n",
        "\n",
        "        # Read the bounding boxes\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, \"r\") as f:\n",
        "                for line in f.readlines():\n",
        "                    cls, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "                    valid_bbox = validate_and_clip_bbox([x_center * w, y_center * h, width * w, height * h], w, h)\n",
        "                    if valid_bbox:\n",
        "                        bboxes.append(valid_bbox)\n",
        "                        class_labels.append(int(cls))\n",
        "\n",
        "        if not bboxes:\n",
        "            print(f\"Skipping image {image_file} due to no valid bounding boxes.\")\n",
        "            continue\n",
        "\n",
        "        # Apply Augmentations\n",
        "        augmented = augmentations(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        augmented_image = augmented[\"image\"]\n",
        "        augmented_bboxes = augmented[\"bboxes\"]\n",
        "        augmented_class_labels = augmented[\"class_labels\"]\n",
        "\n",
        "        # ðŸ”¹ Fix Black Image Issue: Convert Back to uint8 before saving\n",
        "        augmented_image = denormalize_image(augmented_image)\n",
        "\n",
        "        # Save Augmented Image\n",
        "        output_img_path = os.path.join(output_image_folder, image_file)\n",
        "        cv2.imwrite(output_img_path, augmented_image)\n",
        "\n",
        "        # Save Updated Labels\n",
        "        output_label_path = os.path.join(output_label_folder, os.path.splitext(image_file)[0] + \".txt\")\n",
        "        with open(output_label_path, \"w\") as f:\n",
        "            for bbox, cls in zip(augmented_bboxes, augmented_class_labels):\n",
        "                x_center, y_center, width, height = bbox\n",
        "                f.write(f\"{cls} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "        print(f\"Saved Augmented Image: {output_img_path}\")\n",
        "\n",
        "# Apply Augmentation to Train and Validation Sets\n",
        "dataset_dir = \"/content/dataset/dataset\"\n",
        "advanced_augmentations(\n",
        "    image_folder=f\"{dataset_dir}/train/images\",\n",
        "    label_folder=f\"{dataset_dir}/train/labels\",\n",
        "    output_image_folder=f\"{augmented_dir}/train/images\",\n",
        "    output_label_folder=f\"{augmented_dir}/train/labels\"\n",
        ")\n",
        "\n",
        "advanced_augmentations(\n",
        "    image_folder=f\"{dataset_dir}/val/images\",\n",
        "    label_folder=f\"{dataset_dir}/val/labels\",\n",
        "    output_image_folder=f\"{augmented_dir}/val/images\",\n",
        "    output_label_folder=f\"{augmented_dir}/val/labels\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Augmentation completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Test Augmentation on a Random Image"
      ],
      "metadata": {
        "id": "MgQpNn7JcuZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvdWWvtnOcdk"
      },
      "outputs": [],
      "source": [
        "def check_random_augmented_image(image_folder, label_folder):\n",
        "    \"\"\"\n",
        "    Selects a random augmented image, loads its bounding boxes, and visualizes it.\n",
        "    \"\"\"\n",
        "    image_files = os.listdir(image_folder)\n",
        "    if not image_files:\n",
        "        print(\"No augmented images found!\")\n",
        "        return\n",
        "\n",
        "    # Select a random image\n",
        "    random_image = random.choice(image_files)\n",
        "    img_path = os.path.join(image_folder, random_image)\n",
        "    label_path = os.path.join(label_folder, os.path.splitext(random_image)[0] + \".txt\")\n",
        "\n",
        "    # Load the image\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        print(f\"Error loading image: {random_image}\")\n",
        "        return\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
        "    h, w, _ = image.shape  # Get image dimensions\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Load bounding boxes and draw them\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f.readlines():\n",
        "                cls, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "\n",
        "                # Convert YOLO format to pixel coordinates\n",
        "                x_center *= w\n",
        "                y_center *= h\n",
        "                width *= w\n",
        "                height *= h\n",
        "\n",
        "                x_min = x_center - width / 2\n",
        "                y_min = y_center - height / 2\n",
        "\n",
        "                rect = plt.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "                ax.text(x_min, y_min, f\"Class: {int(cls)}\", bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "\n",
        "    plt.title(f\"Augmented Image: {random_image}\")\n",
        "    plt.show()\n",
        "\n",
        "# Run the function to check a random augmented image\n",
        "check_random_augmented_image(\n",
        "    image_folder=\"/content/dataset_augmented/train/images\",\n",
        "    label_folder=\"/content/dataset_augmented/train/labels\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Train YOLOv8"
      ],
      "metadata": {
        "id": "FDIgq04VcgJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmKpdZVbVUiG"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/tomato_ripeness_classifier.yaml\",\n",
        "    epochs=20,\n",
        "    batch=16,\n",
        "    imgsz=640,\n",
        "    project=\"/content/drive/MyDrive/tomato_ripeness_classifier/\",\n",
        "    name=\"yolov8_tomato_ripeness\",\n",
        "    workers=4,\n",
        "    exist_ok=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: Evaluate YOLOv8 Model"
      ],
      "metadata": {
        "id": "72cTWkNicdfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained YOLOv8 model\n",
        "model = YOLO(\"/content/drive/MyDrive/tomato_ripeness_classifier/yolov8_tomato_ripeness/weights/best.pt\")\n",
        "\n",
        "# Run evaluation on the validation set\n",
        "metrics = model.val()\n",
        "\n",
        "# Extract key metrics\n",
        "precision = metrics.box.p  # Precision values per class\n",
        "recall = metrics.box.r      # Recall values per class\n",
        "map50 = metrics.box.map50  # mAP@50 values per class\n",
        "map50_95 = metrics.box.map  # mAP@50-95 values per class\n",
        "classes = metrics.names     # Class names\n",
        "\n",
        "\n",
        "# Convert metrics to lists\n",
        "class_labels = list(classes.values())  # Extract class names\n",
        "num_classes = len(class_labels)\n",
        "\n",
        "# Plot Precision & Recall\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(class_labels, precision, color=\"blue\", label=\"Precision\")\n",
        "plt.bar(class_labels, recall, color=\"red\", alpha=0.7, label=\"Recall\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Precision & Recall per Class\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig(\"/content/precision_recall_plot.png\")\n",
        "plt.show()\n",
        "\n",
        "# Plot mAP@50 and mAP@50-95\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(class_labels, map50, color=\"green\", label=\"mAP@50\")\n",
        "plt.bar(class_labels, map50_95, color=\"orange\", alpha=0.7, label=\"mAP@50-95\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"mAP Scores per Class\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig(\"/content/map_plot.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Evaluation Complete. Saved plots as images.\")\n"
      ],
      "metadata": {
        "id": "NYlIr0AAYZsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9: Test YOLOv8 on a Random Image"
      ],
      "metadata": {
        "id": "fqIfbtIGcZlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/tomato_ripeness_classifier/yolov8_tomato_ripeness/weights/best.pt\")\n",
        "\n",
        "test_image_folder = \"/content/dataset_augmented/val/images\"\n",
        "image_files = os.listdir(test_image_folder)\n",
        "\n",
        "if not image_files:\n",
        "    print(\"No images found in the validation set!\")\n",
        "else:\n",
        "    random_image = random.choice(image_files)\n",
        "    image_path = os.path.join(test_image_folder, random_image)\n",
        "\n",
        "    results = model(image_path, conf=0.5)\n",
        "\n",
        "    # Access the first (and likely only) Results object in the list\n",
        "    results = results[0] # Access the first element (Results object)\n",
        "\n",
        "    results.show()\n",
        "\n",
        "    output_image_path = f\"/content/{random_image}_pred.jpg\"\n",
        "    results.save(filename=output_image_path)\n",
        "\n",
        "    print(f\"Inference complete. Saved result to {output_image_path}.\")"
      ],
      "metadata": {
        "id": "dQv8BxD_ZXlw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU2oP9Pwmo/rNvBjylnBpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}